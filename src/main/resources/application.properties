#	端口号
server.port=8084

###################  mybatis  ########################
  #mapper xml 文件地址
#mybatis.mapper-locations=classpath*:mapper/*Mapper.xml
#  #	数据库url
#spring.datasource.url=jdbc:mysql://localhost:3306/dicfin_iqi?characterEncoding=utf8&serverTimezone=UTC
#  #	数据库用户名
#spring.datasource.username=root
#  #	数据库密码
#spring.datasource.password=123456
#  #	数据库驱动
#spring.datasource.driver-class-name=com.mysql.jdbc.Driver

####################  redis  ########################
# Redis数据库索引（默认为0）
spring.redis.database=0
# Redis服务器地址
spring.redis.host=localhost
# Redis服务器连接端口
spring.redis.port=6379
# Redis服务器连接密码（默认为空）
spring.redis.password=123456
# 连接池最大连接数（使用负值表示没有限制）
spring.redis.jedis.pool.max-active=20
# 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.jedis.pool.max-wait=-1
# 连接池中的最大空闲连接
spring.redis.jedis.pool.max-idle=10
# 连接池中的最小空闲连接
spring.redis.jedis.pool.min-idle=0
# 连接超时时间（毫秒）
spring.redis.timeout=1000

###################  kafka  ########################
#bootstrap-servers：连接kafka的地址，多个地址用逗号分隔
spring.kafka.bootstrap-servers=192.168.67.80:9092

spring.kafka.consumer.group-id=myGroup
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100ms

spring.kafka.consumer.properties.session.timeout.ms=15000
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest

# 若设置大于0的值，客户端会将发送失败的记录重新发送
spring.kafka.producer.retries=0
#当将多个记录被发送到同一个分区时， Producer 将尝试将记录组合到更少的请求中。这有助于提升客户端和服务器端的性能。这个配置控制一个批次的默认大小（以字节为单位）。16384是缺省的配置
spring.kafka.producer.batch-size=16384
#Producer 用来缓冲等待被发送到服务器的记录的总字节数，33554432是缺省配置
spring.kafka.producer.buffer-memory=33554432
#关键字的序列化类
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#值的序列化类
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

###################  elasticsearch  ########################




###################  sharding-jdbc  ########################
# shardingjdbc分片策略
# 配置数据源，给数据源起名称
spring.shardingsphere.datasource.names=m1
# 一个实体类对应两张表，覆盖
spring.main.allow-bean-definition-overriding=true
#配置数据源具体内容，包含连接池，驱动，地址，用户名和密码
spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3307/sharding_db1?serverTimezone=GMT%2B8
spring.shardingsphere.datasource.m1.username=root
spring.shardingsphere.datasource.m1.password=123456
#指定course表分布情况，配置表在哪个数据库里面，表名称都是什么  m1.course_1 , m1.course_2
spring.shardingsphere.sharding.tables.course.actual-data-nodes=m1.course_$->{1..2}
# 指定course表里面主键cid 生成策略  SNOWFLAKE
spring.shardingsphere.sharding.tables.course.key-generator.column=id
spring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE
# 指定分片策略  约定cid值偶数添加到course_1表，如果id是奇数添加到course_2表
spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$->{id % 2 + 1}
# 打开sql输出日志
spring.shardingsphere.props.sql.show=true


